{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")\n",
    "from torch.nn import LayerNorm, Linear, Dropout, Softmax\n",
    "from einops import rearrange, repeat\n",
    "import ssl\n",
    "import copy\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from pathlib import Path\n",
    "import re\n",
    "import torch.backends.cudnn as cudnn\n",
    "import record\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "from operator import truediv\n",
    "import math\n",
    "from PIL import Image\n",
    "import time\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.nn.parameter import Parameter\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import loadmat as loadmat\n",
    "from scipy import io\n",
    "import torch.utils.data as dataf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import einsum\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "cudnn.deterministic = True       \n",
    "cudnn.benchmark = False     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn import LayerNorm,Linear,Dropout,Softmax\n",
    "import copy\n",
    "\n",
    "def INF(B,H,W):\n",
    "\n",
    "    return -torch.diag(torch.tensor(float(\"inf\")).cuda().repeat(H),0).unsqueeze(0).repeat(B*W,1,1)    \n",
    "\n",
    "class HetConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,padding = None, bias = None,p = 64, g = 64):\n",
    "        super(HetConv, self).__init__()\n",
    "        \n",
    "        self.ACmix = ACmix(in_channels, out_channels)\n",
    "        self.pwc = nn.Conv2d(in_channels, out_channels, kernel_size=1,groups=p, stride = stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ACmix(x) + self.pwc(x)   \n",
    "\n",
    "class MCrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0.1, proj_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads    \n",
    "        head_dim = dim // num_heads   \n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "        self.wk = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "        self.wv = nn.Linear(head_dim, dim , bias=qkv_bias)   \n",
    "        self.proj = nn.Linear(dim * num_heads, dim) \n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(1, num_heads, 8 + 1, 64))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        q = self.wq(x[:, 0:1, ...].reshape(B, 1, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  \n",
    "        k = self.wk(x.reshape(B, N, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  \n",
    "        v = self.wv(x.reshape(B, N, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3) \n",
    "        v = v + self.position_embeddings\n",
    "        attn = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale \n",
    "        \n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        x = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        x = ((x + v)[:, :, 0:1, ...]).transpose(1, 2)\n",
    "        x = x.reshape(B, 1, C * self.num_heads)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class DWConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv2d(512, 64, kernel_size = 3, groups= 64, padding=kernel_size//2)\n",
    "        self.pointwise_conv = nn.Conv2d(512, 64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.depthwise_conv(x) + self.pointwise_conv(x)\n",
    "\n",
    "def position(H, W, is_cuda=True):\n",
    "    if is_cuda:\n",
    "        loc_w = torch.linspace(-1.0, 1.0, W).cuda().unsqueeze(0).repeat(H, 1)\n",
    "        loc_h = torch.linspace(-1.0, 1.0, H).cuda().unsqueeze(1).repeat(1, W)\n",
    "    else:\n",
    "        loc_w = torch.linspace(-1.0, 1.0, W).unsqueeze(0).repeat(H, 1)\n",
    "        loc_h = torch.linspace(-1.0, 1.0, H).unsqueeze(1).repeat(1, W)\n",
    "    loc = torch.cat([loc_w.unsqueeze(0), loc_h.unsqueeze(0)], 0).unsqueeze(0)\n",
    "    return loc\n",
    "\n",
    "\n",
    "def stride(x, stride):\n",
    "    b, c, h, w = x.shape\n",
    "    return x[:, :, ::stride, ::stride]\n",
    "\n",
    "def init_rate_half(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0.5)\n",
    "\n",
    "def init_rate_0(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0.)\n",
    "\n",
    "\n",
    "class ACmix(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_att=7, head=4, kernel_conv=3, stride=1, dilation=1):\n",
    "        super(ACmix, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes = out_planes\n",
    "        self.head = head\n",
    "        self.kernel_att = kernel_att\n",
    "        self.kernel_conv = kernel_conv\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.rate1 = torch.nn.Parameter(torch.Tensor(1))\n",
    "        self.rate2 = torch.nn.Parameter(torch.Tensor(1))\n",
    "        self.head_dim = self.out_planes // self.head\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
    "        self.conv_p = nn.Conv2d(2, self.head_dim, kernel_size=1)\n",
    "\n",
    "        self.padding_att = (self.dilation * (self.kernel_att - 1) + 1) // 2\n",
    "        self.pad_att = torch.nn.ReflectionPad2d(self.padding_att)\n",
    "        self.unfold = nn.Unfold(kernel_size=self.kernel_att, padding=0, stride=self.stride)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "        self.fc = nn.Conv2d(3*self.head, self.kernel_conv * self.kernel_conv, kernel_size=1, bias=False)\n",
    "        self.dep_conv = nn.Conv2d(self.kernel_conv * self.kernel_conv * self.head_dim, out_planes, kernel_size=self.kernel_conv, bias=True, groups=self.head_dim, padding=1, stride=stride)\n",
    "\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        init_rate_half(self.rate1)\n",
    "        init_rate_half(self.rate2)\n",
    "        kernel = torch.zeros(self.kernel_conv * self.kernel_conv, self.kernel_conv, self.kernel_conv)\n",
    "        for i in range(self.kernel_conv * self.kernel_conv):\n",
    "            kernel[i, i//self.kernel_conv, i%self.kernel_conv] = 1.\n",
    "        kernel = kernel.squeeze(0).repeat(self.out_planes, 1, 1, 1)\n",
    "        self.dep_conv.weight = nn.Parameter(data=kernel, requires_grad=True)\n",
    "        self.dep_conv.bias = init_rate_0(self.dep_conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.conv1(x), self.conv2(x), self.conv3(x)\n",
    "        scaling = float(self.head_dim) ** -0.5\n",
    "        b, c, h, w = q.shape\n",
    "        h_out, w_out = h//self.stride, w//self.stride\n",
    "\n",
    "        pe = self.conv_p(position(h, w, x.is_cuda))\n",
    "\n",
    "        q_att = q.view(b*self.head, self.head_dim, h, w) * scaling\n",
    "        k_att = k.view(b*self.head, self.head_dim, h, w)\n",
    "        v_att = v.view(b*self.head, self.head_dim, h, w)\n",
    "\n",
    "        if self.stride > 1:\n",
    "            q_att = stride(q_att, self.stride)\n",
    "            q_pe = stride(pe, self.stride)\n",
    "        else:\n",
    "            q_pe = pe\n",
    "\n",
    "        unfold_k = self.unfold(self.pad_att(k_att)).view(b*self.head, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out) \n",
    "        unfold_rpe = self.unfold(self.pad_att(pe)).view(1, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out) \n",
    "        att = (q_att.unsqueeze(2)*(unfold_k + q_pe.unsqueeze(2) - unfold_rpe)).sum(1)\n",
    "        att = self.softmax(att)\n",
    "        \n",
    "        out_att = self.unfold(self.pad_att(v_att)).view(b*self.head, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out)\n",
    "        out_att = (att.unsqueeze(1) * out_att).sum(2).view(b, self.out_planes, h_out, w_out)\n",
    "\n",
    "        f_all = self.fc(torch.cat([q.view(b, self.head, self.head_dim, h*w), k.view(b, self.head, self.head_dim, h*w), v.view(b, self.head, self.head_dim, h*w)], 1))\n",
    "        f_conv = f_all.permute(0, 2, 1, 3).reshape(x.shape[0], -1, x.shape[-2], x.shape[-1])\n",
    "        \n",
    "        out_conv = self.dep_conv(f_conv)\n",
    "\n",
    "        return self.rate1 * out_att + self.rate2 * out_conv\n",
    "    \n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.fc1 = Linear(dim, 512)  \n",
    "        self.fc2 = Linear(512, dim)  \n",
    "        self.act_fn = nn.GELU()  \n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.dwconv = DWConv(512, 64, 3)\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc1.weight)   \n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
    "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        x = self.fc1(x)     \n",
    "        x = self.act_fn(x)     \n",
    "        x = self.dropout(x) \n",
    "        x1 = x.unsqueeze(1)\n",
    "        x1 = x1.transpose(1, 3)\n",
    "        x1 = self.dwconv(x1)\n",
    "        x1 = x1.squeeze(-1)\n",
    "        x1 = x1.transpose(1, 2)\n",
    "        x1 = x1.cpu().detach().numpy()\n",
    "        x1 = np.repeat(x1, 8, axis=2)\n",
    "        x1 = torch.tensor(x1).to('cuda:0')\n",
    "        x = x1 + x\n",
    "        x = self.fc2(x)     \n",
    "        x = self.dropout(x)     \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Block, self).__init__()\n",
    "        self.hidden_size = dim\n",
    "        self.attention_norm = LayerNorm(dim, eps=1e-6)  \n",
    "\n",
    "        self.ffn_norm = LayerNorm(dim, eps=1e-6)   \n",
    "        self.ffn = Mlp(dim)    \n",
    "        self.attn = MCrossAttention(dim = dim)   \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,3,1,1),\n",
    "            CBAM(64),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, groups= 64),\n",
    "            CBAM(64),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, 1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = x  \n",
    "        x = self.attention_norm(x) \n",
    "        x = self.attn(x) \n",
    "        x = x + h\n",
    "        \n",
    "        h = x \n",
    "        x = self.ffn_norm(x) \n",
    "        x = self.ffn(x)\n",
    "        x = x + h  \n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads= 8, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0.1, attn_drop=0.1,\n",
    "                 drop_path=0.1, act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=False):\n",
    "        super().__init__()    \n",
    "        self.layer = nn.ModuleList()   \n",
    "        self.encoder_norm = LayerNorm(dim, eps=1e-6)\n",
    "        \n",
    "        for _ in range(4):   \n",
    "            layer = Block(dim)   \n",
    "            self.layer.append(copy.deepcopy(layer))   \n",
    "        self.skipcat = nn.ModuleList([])\n",
    "        for _ in range(2):\n",
    "            self.skipcat.append(nn.Conv2d(9, 9, [1, 2], 1, 0))\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        last_output = []\n",
    "        nl = 0\n",
    "        for layer_block in self.layer:\n",
    "            last_output.append(x)\n",
    "            if nl > 1:             \n",
    "                 x = self.skipcat[nl-2](torch.cat([x.unsqueeze(3), last_output[nl-2].unsqueeze(3)], dim=3)).squeeze(3)\n",
    "            x = layer_block(x)\n",
    "            nl += 1\n",
    "        encoded = self.encoder_norm(x)  \n",
    "        return encoded[:,0]   \n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "\n",
    "        if inter_channels is None:\n",
    "            inter_channels = in_channels // 2\n",
    "\n",
    "        self.theta = nn.Conv2d(in_channels, inter_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = nn.Conv2d(in_channels, inter_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.g = nn.Conv2d(in_channels, inter_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.operation_function = self._operation\n",
    "\n",
    "        self.out_conv = nn.Conv2d(inter_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def _operation(self, theta, phi, g):\n",
    "        b, c, h, w = theta.size() \n",
    "        theta = theta.view(b, c, h * w).permute(0, 2, 1) \n",
    "        phi = phi.view(b, c, h * w)              \n",
    "        t = torch.matmul(theta, phi)  \n",
    "        t = torch.softmax(t, dim=-1) \n",
    "        g = g.view(b, c, h * w).permute(0, 2, 1) \n",
    "        y = torch.matmul(t, g)        \n",
    "        y = y.permute(0, 2, 1).contiguous().view(b, c, h, w) \n",
    "        y = self.relu(self.out_conv(y))\n",
    "        return y  \n",
    "\n",
    "    def forward(self, x):\n",
    "        theta = self.theta(x)\n",
    "        phi = self.phi(x) \n",
    "        g = self.g(x)\n",
    "        y = self.operation_function(theta, phi, g)\n",
    "        z = y + x\n",
    "        return z\n",
    "\n",
    "class ChannelAttention3D(nn.Module):\n",
    "    def __init__(self, in_planes, ratio):\n",
    "        super(ChannelAttention3D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv3d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_planes // ratio, in_planes, 1, bias=False),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "class SpatialAttention3D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(SpatialAttention3D, self).__init__()\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.conv = nn.Conv3d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class CBAM3D(nn.Module):\n",
    "    def __init__(self, in_planes, ratio, kernel_size):\n",
    "        super(CBAM3D, self).__init__()\n",
    "        self.channel_att = ChannelAttention3D(in_planes, ratio)\n",
    "        self.spatial_att = SpatialAttention3D(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.channel_att(x) * x\n",
    "        out = self.spatial_att(out) * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = self.sigmoid(avg_out + max_out).view(x.size(0), x.size(1), 1, 1)\n",
    "        return out\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_out = self.channel_attention(x) * x\n",
    "        spatial_out = self.spatial_attention(channel_out) * channel_out\n",
    "        return spatial_out\n",
    "\n",
    "class MFT(nn.Module):\n",
    "    def __init__(self, FM, NC, NCLidar, Classes, HSIOnly):\n",
    "        super(MFT, self).__init__()\n",
    "        self.HSIOnly = HSIOnly\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, (9, 3, 3), padding=(0, 1, 1), stride=1),   \n",
    "            CBAM3D(8, 4, 7),\n",
    "            nn.BatchNorm3d(8),     \n",
    "            nn.ReLU(),\n",
    "        )   \n",
    "        self.conv6 = nn.Sequential(\n",
    "            HetConv(8 * (NC-8), FM*4,\n",
    "                p = 1,\n",
    "                g = (FM*4)//4 if (8 * (NC-8))%FM == 0 else (FM*4)//8,\n",
    "                   ),     \n",
    "            nn.BatchNorm2d(FM*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.last_BandSize = NC//2//2//2\n",
    "        self.lidarConv = nn.Sequential(\n",
    "            nn.Conv2d(NCLidar,16,3,1,1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(16,32,3,1,1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32,FM*4,3,1,1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.ca = TransformerEncoder(FM*4)        \n",
    "        self.out3 = nn.Linear(FM*4 , Classes)     \n",
    "        self.out2 = nn.Linear(FM*4 , 32)\n",
    "        self.nlocal = NonLocalBlock(FM*4)\n",
    "        self.dropout = nn.Dropout(0.1)      \n",
    "        torch.nn.init.xavier_uniform_(self.out3.weight)    \n",
    "        torch.nn.init.normal_(self.out3.bias, std=1e-6)    \n",
    "        self.token_wA = nn.Parameter(torch.empty(1, 8, 64),     \n",
    "                                     requires_grad=True) \n",
    "        torch.nn.init.xavier_normal_(self.token_wA)\n",
    "       \n",
    "        self.token_wV = nn.Parameter(torch.empty(1, 64, 64),\n",
    "                                     requires_grad=True)  \n",
    "        torch.nn.init.xavier_normal_(self.token_wV)       \n",
    "        \n",
    "        self.token_wA_L = nn.Parameter(torch.empty(1, 1, 64),\n",
    "                                     requires_grad=True)  \n",
    "        torch.nn.init.xavier_normal_(self.token_wA_L)  \n",
    "        self.token_wV_L = nn.Parameter(torch.empty(1, 64, 64),\n",
    "                                     requires_grad=True)  \n",
    "        torch.nn.init.xavier_normal_(self.token_wV_L)\n",
    "    \n",
    "    def forward(self, x1, x2): \n",
    "        x1 = x1.reshape(x1.shape[0],-1,patchsize,patchsize)  \n",
    "        x2 = x2.reshape(x2.shape[0],-1,patchsize,patchsize)  \n",
    "        \n",
    "        x1 = x1.unsqueeze(1)    \n",
    "        x1 = self.conv5(x1)     \n",
    "        x1 = x1.reshape(x1.shape[0],-1,patchsize,patchsize)  \n",
    "        \n",
    "        x1 = self.conv6(x1)   \n",
    "\n",
    "        x2 = self.lidarConv(x2)\n",
    "        x2 = self.nlocal(x2)\n",
    "        x2 = x2.reshape(x2.shape[0],-1,patchsize**2)  \n",
    "\n",
    "        x2 = x2.transpose(-1, -2)   \n",
    "        wa_L = self.token_wA_L.expand(x1.shape[0],-1,-1)  \n",
    "        wa_L = rearrange(wa_L, 'b h w -> b w h')  \n",
    "        A_L = torch.einsum('bij,bjk->bik', x2, wa_L) \n",
    "        A_L = rearrange(A_L, 'b h w -> b w h')  \n",
    "        A_L = A_L.softmax(dim=-1) \n",
    "        wv_L = self.token_wV_L.expand(x2.shape[0],-1,-1)  \n",
    "        VV_L = torch.einsum('bij,bjk->bik', x2, wv_L) \n",
    "        x2 = torch.einsum('bij,bjk->bik', A_L, VV_L)  \n",
    "        \n",
    "        x1 = x1.flatten(2) \n",
    "        x1 = x1.transpose(-1, -2) \n",
    "              \n",
    "        wa = self.token_wA.expand(x1.shape[0],-1,-1)  \n",
    "        wa = rearrange(wa, 'b h w -> b w h')  \n",
    "        A = torch.einsum('bij,bjk->bik', x1, wa)  \n",
    "        A = rearrange(A, 'b h w -> b w h')  \n",
    "        A = A.softmax(dim=-1)\n",
    "        wv = self.token_wV.expand(x1.shape[0],-1,-1) \n",
    "        VV = torch.einsum('bij,bjk->bik', x1, wv) \n",
    "        T = torch.einsum('bij,bjk->bik', A, VV) \n",
    "        x = torch.cat((x2, T), dim = 1) \n",
    "        embeddings = x \n",
    "        x = self.ca(embeddings)  \n",
    "        x = x.reshape(x.shape[0],-1)   \n",
    "        out2 = x\n",
    "        out3 = self.out3(x)\n",
    "        return out3, out2\n",
    "\n",
    "batchsize = 64 \n",
    "patchsize = 11 \n",
    "model = MFT(16, 144, 1, 15, False).to(\"cuda\") \n",
    "summary(model, [(144,121),(1,121)], device = 'cuda')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c54cd79c36f9de90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The least populated class in y has only .* members, which is less than n_splits=5.\", category=UserWarning)\n",
    "\n",
    "DATA2_List = []\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "datasetNames = ['Houston']\n",
    "\n",
    "patchsize = 11   \n",
    "batchsize = 64   \n",
    "testSizeNumber = 500  \n",
    "EPOCH = 300\n",
    "BandSize = 1   \n",
    "LR = 5e-4  \n",
    "FM = 16     \n",
    "HSIOnly = False\n",
    "FileName = 'MFT'\n",
    "\n",
    "w1 = 0.10\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]     \n",
    "    list_diag = np.diag(confusion_matrix)   \n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)     \n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))     \n",
    "    average_acc = np.mean(each_acc)    \n",
    "    return each_acc, average_acc    \n",
    "\n",
    "def reports (xtest,xtest2,ytest,name,model,iterNum):\n",
    "    pred_y = np.empty((len(ytest)), dtype=np.float32)      \n",
    "    number = len(ytest) // testSizeNumber\n",
    "\n",
    "    for i in range(number):\n",
    "        temp = xtest[i * testSizeNumber:(i + 1) * testSizeNumber, :, :] \n",
    "        temp = temp.cuda()  \n",
    "        temp1 = xtest2[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "        temp1 = temp1.cuda()\n",
    "\n",
    "        temp2, temp3 = model(temp,temp1)\n",
    "\n",
    "        svm_classifier = pickle.load(open(name+'/best_model_HSIAMS_all_'+str(iterNum)+'.h5', 'rb'))\n",
    "        pred_y[i * testSizeNumber:(i + 1) * testSizeNumber] = svm_classifier.predict(temp3.cpu().detach().numpy())\n",
    "        del temp, temp1, temp2, temp3\n",
    "    \n",
    "    if (i + 1) * testSizeNumber < len(ytest):\n",
    "        temp = xtest[(i + 1) * testSizeNumber:len(ytest), :, :]\n",
    "        temp = temp.cuda()\n",
    "        temp1 = xtest2[(i + 1) * testSizeNumber:len(ytest), :, :]\n",
    "        temp1 = temp1.cuda()\n",
    "\n",
    "        temp2, temp3 = model(temp,temp1)\n",
    "        svm_classifier = pickle.load(open(name+'/best_model_HSIAMS_all_'+str(iterNum)+'.h5', 'rb'))\n",
    "        pred_y[(i + 1) * testSizeNumber:len(ytest)] = svm_classifier.predict(temp3.cpu().detach().numpy())\n",
    "        del temp, temp1, temp2, temp3\n",
    "    pred_y = torch.from_numpy(pred_y).long()\n",
    "    \n",
    "    oa = accuracy_score(ytest, pred_y)     \n",
    "    confusion = confusion_matrix(ytest, pred_y)     \n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)  \n",
    "    kappa = cohen_kappa_score(ytest, pred_y) \n",
    "    return confusion, oa*100, each_acc*100, aa*100, kappa*100\n",
    "\n",
    "def set_seed(seed):     \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)    \n",
    "    np.random.seed(seed)   \n",
    "\n",
    "sample_counts = [198, 190, 227, 188, 186, 196, 196, 191, 193, 191, 234, 192, 246, 216, 227]\n",
    "\n",
    "class_weights = {i: 1.0 / count for i, count in enumerate(sample_counts)}\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        weights = [1 / count for count in sample_counts]\n",
    "        class_weights = torch.tensor(weights).to('cuda:0')\n",
    "        cross_entropy_loss = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        output = output.to('cuda:0')\n",
    "        target = target.to('cuda:0')\n",
    "        cross_entropy_loss = cross_entropy_loss(output, target)\n",
    "        return cross_entropy_loss\n",
    "\n",
    "def train():\n",
    "    for BandSize in [1]:\n",
    "        for datasetName in datasetNames:\n",
    "                print(\"----------------------------------Training for \",datasetName,\" ---------------------------------------------\")\n",
    "                try:\n",
    "                    os.makedirs(datasetName)   \n",
    "                except FileExistsError:\n",
    "                    pass\n",
    "                data1Name = ''\n",
    "                data2Name = ''\n",
    "                if datasetName in [\"Houston\",\"MUUFL\"]:\n",
    "                    data1Name = datasetName\n",
    "                    data2Name = \"LIDAR\"\n",
    "                else:\n",
    "                    for dataName in DATA2_List:\n",
    "                        dataNameToCheck = re.compile(dataName)\n",
    "                        matchObj = dataNameToCheck.search(datasetName)\n",
    "                        if matchObj:\n",
    "                            data1Name = datasetName.replace(dataName,\"\")\n",
    "                            data2Name = dataName\n",
    "                \n",
    "                HSI = io.loadmat('./../'+data1Name+'11x11/HSI_Train.mat')      \n",
    "                TrainPatch = HSI['block']       \n",
    "                TrainPatch = TrainPatch.astype(np.float32)      \n",
    "                NC = TrainPatch.shape[3] \n",
    "                \n",
    "                LIDAR = io.loadmat('./../'+data1Name+'11x11/'+data2Name+'_Train.mat')\n",
    "                TrainPatch2 = LIDAR['block2']\n",
    "                TrainPatch2 = TrainPatch2.astype(np.float32)\n",
    "                TrainPatch2 = TrainPatch2.reshape(-1, 11, 11, 1)\n",
    "                NCLIDAR = TrainPatch2.shape[3] \n",
    "\n",
    "                label = io.loadmat('./../'+data1Name+'11x11/HSI_Train_label.mat')\n",
    "                TrLabel = label['Tr_label']\n",
    "                \n",
    "                HSI = io.loadmat('./../'+data1Name+'11x11/HSI_Test.mat')\n",
    "                TestPatch = HSI['block1']\n",
    "                TestPatch = TestPatch.astype(np.float32)\n",
    "\n",
    "                LIDAR = io.loadmat('./../'+data1Name+'11x11/'+data2Name+'_Test.mat')\n",
    "                TestPatch2 = LIDAR['block3']\n",
    "                TestPatch2 = TestPatch2.astype(np.float32)\n",
    "                TestPatch2 = TestPatch2.reshape(-1, 11, 11, 1)\n",
    "\n",
    "                label = io.loadmat('./../'+data1Name+'11x11/HSI_Test_label.mat')\n",
    "                TsLabel = label['Te_label']\n",
    "                \n",
    "                \n",
    "                TrainPatch1 = torch.from_numpy(TrainPatch).to(torch.float32)  \n",
    "                TrainPatch1 = TrainPatch1.permute(0,3,1,2)  \n",
    "                TrainPatch1 = TrainPatch1.reshape(TrainPatch1.shape[0],TrainPatch1.shape[1],-1).to(torch.float32)\n",
    "                TrainPatch2 = torch.from_numpy(TrainPatch2).to(torch.float32)\n",
    "                TrainPatch2 = TrainPatch2.permute(0,3,1,2)\n",
    "                TrainPatch2 = TrainPatch2.reshape(TrainPatch2.shape[0],TrainPatch2.shape[1],-1).to(torch.float32)\n",
    "                TrainLabel1 = torch.from_numpy(TrLabel)-1\n",
    "                TrainLabel1 = TrainLabel1.long()\n",
    "                TrainLabel1 = TrainLabel1.reshape(-1) \n",
    "\n",
    "                TestPatch1 = torch.from_numpy(TestPatch).to(torch.float32)\n",
    "                TestPatch1 = TestPatch1.permute(0,3,1,2)\n",
    "                TestPatch1 = TestPatch1.reshape(TestPatch1.shape[0],TestPatch1.shape[1],-1).to(torch.float32)\n",
    "                TestPatch2 = torch.from_numpy(TestPatch2).to(torch.float32)\n",
    "                TestPatch2 = TestPatch2.permute(0,3,1,2)\n",
    "                TestPatch2 = TestPatch2.reshape(TestPatch2.shape[0],TestPatch2.shape[1],-1).to(torch.float32)\n",
    "                TestLabel1 = torch.from_numpy(TsLabel)-1\n",
    "                TestLabel1 = TestLabel1.long()\n",
    "                TestLabel1 = TestLabel1.reshape(-1)\n",
    "                \n",
    "                Classes = len(np.unique(TrainLabel1)) \n",
    "                dataset = dataf.TensorDataset(TrainPatch1, TrainPatch2, TrainLabel1)\n",
    "                if data1Name in ['Berlin']:\n",
    "                    train_loader = dataf.DataLoader(dataset, batch_size=batchsize, shuffle=True, num_workers= 0)\n",
    "                else:\n",
    "                    train_loader = dataf.DataLoader(dataset, batch_size=batchsize, shuffle=True, num_workers= 4)  #  数据加载器    \n",
    "                print(\"HSI Train data shape = \", TrainPatch1.shape)\n",
    "                print(data2Name + \" Train data shape = \", TrainPatch2.shape)\n",
    "                print(\"Train label shape = \", TrainLabel1.shape)\n",
    "\n",
    "                print(\"HSI Test data shape = \", TestPatch1.shape)\n",
    "                print(data2Name + \" Test data shape = \", TestPatch2.shape)\n",
    "                print(\"Test label shape = \", TestLabel1.shape)\n",
    "\n",
    "                print(\"Number of Classes = \", Classes)\n",
    "                KAPPA = []\n",
    "                OA = []\n",
    "                AA = []\n",
    "                ELEMENT_ACC = np.zeros((3, Classes))\n",
    "                \n",
    "                set_seed(42)\n",
    "                for iterNum in range(3):\n",
    "                    model = MFT(FM, NC, NCLIDAR, Classes, HSIOnly).cuda()\n",
    "                    summary(model, [(NC, patchsize**2),(NCLIDAR,patchsize**2)])\n",
    "                    \n",
    "                    optimizer = torch.optim.Adam([\n",
    "                        {'params': model.parameters(), 'lr':LR, 'weight_decay':5e-3},  \n",
    "                    ])\n",
    "                    criterion = CustomLoss()\n",
    "                    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "                    BestAcc = 0\n",
    "                         \n",
    "                    torch.cuda.synchronize()  \n",
    "                    start = time.time()\n",
    "                    for epoch in range(EPOCH):    \n",
    "        \n",
    "                        for step, (b_x1, b_x2, b_y) in enumerate(train_loader):\n",
    "                            \n",
    "                            b_x1 = b_x1.cuda()\n",
    "                            b_y = b_y.cuda()\n",
    "                                      \n",
    "                            b_x2 = b_x2.cuda()\n",
    "                            \n",
    "                            out, intermediate_output = model(b_x1, b_x2)\n",
    "                            \n",
    "                            svm_classifier = svm.SVC(kernel='linear', tol=1e-9, class_weight=class_weights)\n",
    "                            grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
    "                            grid_search.fit(intermediate_output.cpu().detach().numpy(), b_y.cpu().detach().numpy())\n",
    "                            best_C = grid_search.best_params_['C']\n",
    "                            svm_classifier = svm.SVC(kernel='linear', C=best_C, tol=1e-9, class_weight=class_weights)\n",
    "                            svm_classifier.fit(intermediate_output.cpu().detach().numpy(), b_y.cpu().detach().numpy())\n",
    "                            weights = svm_classifier.coef_\n",
    "                            bias = svm_classifier.intercept_\n",
    "                            weights = torch.tensor(weights, dtype=torch.float32).to('cuda')\n",
    "                            bias = torch.tensor(bias, dtype=torch.float32).to('cuda')    \n",
    "                            loss = criterion(out, b_y)\n",
    "                            total_hinge_loss = 0\n",
    "                            for i in range(64):\n",
    "                                svm_loss = torch.sum(torch.abs(torch.matmul(weights, intermediate_output[i:i+1, :].transpose(0,1)) + bias.unsqueeze(1)) / torch.norm(weights))\n",
    "                                total_hinge_loss += svm_loss\n",
    "                            average_hinge_loss = torch.mean(torch.max(torch.tensor(0), 1 - total_hinge_loss))\n",
    "                            loss = loss + w1 * average_hinge_loss\n",
    "                            \n",
    "                            optimizer.zero_grad()  \n",
    "                            loss.backward()  \n",
    "                            optimizer.step()  \n",
    "                            \n",
    "                            if step % 50 == 0:    \n",
    "                                model.eval()  \n",
    "                                pred_y = np.empty((len(TestLabel1)), dtype='float32')\n",
    "                                number = len(TestLabel1) // testSizeNumber\n",
    "                                for i in range(number):\n",
    "                                    temp = TestPatch1[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "                                    temp = temp.cuda()\n",
    "                                    temp1 = TestPatch2[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "                                    temp1 = temp1.cuda()\n",
    "                                    if HSIOnly:\n",
    "                                        temp2 = model(temp, temp1)\n",
    "                                        temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "                                        pred_y[i * testSizeNumber:(i + 1) * testSizeNumber] = temp3.cpu()\n",
    "                                        del temp, temp2, temp3\n",
    "                                    else:\n",
    "                                        temp2, temp3 = model(temp, temp1)\n",
    "                                        pred_y[i * testSizeNumber:(i + 1) * testSizeNumber] = svm_classifier.predict(temp3.cpu().detach().numpy())\n",
    "                                        del temp, temp1, temp2, temp3\n",
    "                                \n",
    "                                if (i + 1) * testSizeNumber < len(TestLabel1):\n",
    "                                    temp = TestPatch1[(i + 1) * testSizeNumber:len(TestLabel1), :, :]\n",
    "                                    temp = temp.cuda()\n",
    "                                    temp1 = TestPatch2[(i + 1) * testSizeNumber:len(TestLabel1), :, :]\n",
    "                                    temp1 = temp1.cuda()\n",
    "                                    if HSIOnly:\n",
    "                                        temp2 = model(temp, temp1)\n",
    "                                        temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "                                        pred_y[(i + 1) * testSizeNumber:len(TestLabel1)] = temp3.cpu()\n",
    "                                        del temp, temp2, temp3\n",
    "                                    else:\n",
    "                                        temp2, temp3 = model(temp, temp1)\n",
    "                                        pred_y[(i + 1) * testSizeNumber:len(TestLabel1)] = svm_classifier.predict(temp3.cpu().detach().numpy())\n",
    "                                        del temp, temp1, temp2, temp3\n",
    "                                         \n",
    "                                pred_y = torch.from_numpy(pred_y).long()\n",
    "                                accuracy = torch.sum(pred_y == TestLabel1).type(torch.FloatTensor) / TestLabel1.size(0)\n",
    "                                \n",
    "                                print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.4f' % (accuracy*100))\n",
    "                                if accuracy > BestAcc:\n",
    "\n",
    "                                    BestAcc = accuracy\n",
    "                                    best_epoch = epoch\n",
    "                                    \n",
    "                                    torch.save(model.state_dict(), datasetName+'/net_params_AMS_all'+FileName+'.pkl')\n",
    "                                    pickle.dump(svm_classifier, open(datasetName+'/best_model_HSIAMS_all_'+str(iterNum)+'.h5', 'wb'))\n",
    "                                model.train()\n",
    "                        scheduler.step()\n",
    "                    print(f\"The best epoch is {best_epoch+1} epoch , The accuracy is {BestAcc}\")\n",
    "                    \n",
    "                    torch.cuda.synchronize()\n",
    "                    end = time.time()\n",
    "                    print(end - start)\n",
    "                    Train_time = end - start\n",
    "                    \n",
    "                    model.load_state_dict(torch.load(datasetName+'/net_params_AMS_all'+FileName+'.pkl'))\n",
    "                    \n",
    "                    model.eval()\n",
    "                    confusion, oa, each_acc, aa, kappa = reports(TestPatch1,TestPatch2,TestLabel1,datasetName,model,iterNum)\n",
    "                    KAPPA.append(kappa)\n",
    "                    OA.append(oa)\n",
    "                    AA.append(aa)\n",
    "                    ELEMENT_ACC[iterNum, :] = each_acc\n",
    "                    torch.save(model, datasetName+'/best_model_AMS_all'+FileName+'_BandSize'+str(BandSize)+'_Iter'+str(iterNum)+'.pt')\n",
    "                    pickle.dump(svm_classifier, open(datasetName+'/best_model_HSIAMS_all_'+str(iterNum)+'.h5', 'wb'))\n",
    "                    \n",
    "                    print(\"OA = \", oa)\n",
    "                    print(\"AA = \", aa)\n",
    "                    print(\"KAPPA = \", kappa)\n",
    "                    \n",
    "                print(\"----------\" + datasetName + \" Training Finished -----------\")\n",
    "                record.record_output(OA, AA, KAPPA, ELEMENT_ACC,'./' + datasetName +'/'+FileName+'_BandSize'+str(BandSize)+'_Report_AMS_all' + datasetName +'.txt')\n",
    "\n",
    "train()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8413c7365b55502e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
